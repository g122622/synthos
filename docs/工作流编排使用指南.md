# Synthos 工作流编排使用指南

> 版本：v1.0  
> 更新日期：2026-02-07  
> 适用对象：Synthos 用户

---

## 📖 目录

1. [什么是工作流编排](#1-什么是工作流编排)
2. [快速开始](#2-快速开始)
3. [工作流编排界面](#3-工作流编排界面)
4. [节点类型说明](#4-节点类型说明)
5. [创建和编辑工作流](#5-创建和编辑工作流)
6. [运行和监控工作流](#6-运行和监控工作流)
7. [常见场景示例](#7-常见场景示例)
8. [常见问题](#8-常见问题)

---

## 1. 什么是工作流编排

### 1.1 简介

Synthos 的**工作流编排**功能允许你以**可视化、拖拽式**的方式定义和管理数据处理流程，无需编写代码即可：

- 📊 **可视化定义流程**：通过拖拽节点和连线构建 DAG（有向无环图）
- ⚡ **并行执行**：支持多个任务同时运行，提升处理效率
- 🔀 **条件分支**：根据执行结果动态选择分支路径
- 🔄 **自动重试**：节点失败后自动重试，提高稳定性
- 📝 **实时监控**：查看每个节点的执行状态和输出结果
- 🛠️ **断点续跑**：流程失败后可从断点继续执行

### 1.2 默认工作流

Synthos 内置了一个标准的数据处理工作流 `default-pipeline`，包含以下步骤：

```
[开始] → [提供数据] → [预处理] → [AI 摘要] → [生成向量嵌入] → [兴趣度评分] → [结束]
```

该工作流每小时自动执行一次，处理最新的聊天记录。

---

## 2. 快速开始

### 2.1 访问工作流编排页面

1. 启动 Synthos 系统（参考主 README）
2. 在浏览器中打开 WebUI：`http://localhost:5173`
3. 点击左侧导航栏的 **"🔀流程编排"** 进入工作流页面

### 2.2 查看默认工作流

进入工作流页面后，你会看到：

- **画布区域**（中央）：显示工作流的节点和连线
- **节点面板**（左侧）：可拖拽的节点类型列表
- **属性面板**（右侧）：选中节点后显示其配置
- **执行面板**（底部）：显示执行历史和当前状态

默认工作流会自动加载到画布上。

---

## 3. 工作流编排界面

### 3.1 画布区域

**功能**：
- 缩放：鼠标滚轮或工具栏的 +/- 按钮
- 平移：按住鼠标左键拖拽
- 选中节点：单击节点
- 多选：按住 Shift 并框选
- 删除：选中后按 Delete 键

**节点状态颜色**：
- 🔘 灰色边框：等待执行
- 🔵 蓝色边框 + 脉冲动画：正在执行
- 🟢 绿色边框：执行成功
- 🔴 红色边框：执行失败
- 🟡 黄色边框：已跳过
- ⚫ 暗灰色边框：已取消

### 3.2 节点面板（左侧）

包含以下可拖拽的节点类型：

- **开始节点** ：流程起点
- **结束节点** ：流程终点
- **任务节点** ：调用 Synthos 内置任务（如 ProvideData、Preprocess）
- **条件节点** ：根据条件选择分支
- **并行节点** ：标记并行分支的起始/结束
- **脚本节点** ：执行自定义 JavaScript 代码
- **HTTP 节点** ：调用外部 API

### 3.3 属性面板（右侧）

选中节点后，属性面板会显示该节点的详细配置：

- **基本信息**：节点名称、类型
- **任务配置**（仅任务节点）：任务类型、参数
- **重试策略**：重试次数、超时时间
- **失败处理**：是否跳过失败
- **条件表达式**（仅条件节点）：分支条件

### 3.4 执行面板（底部）

显示工作流的执行历史：

- **执行 ID**：唯一标识每次执行
- **状态**：运行中 / 成功 / 失败
- **开始时间**：执行开始的时间戳
- **耗时**：执行总时长
- **节点进度**：已完成节点数 / 总节点数

点击某条记录可在画布上查看该次执行的详细状态。

---

## 4. 节点类型说明

### 4.1 开始节点 (Start)

- **作用**：标记工作流的起点（非必需，DAG 引擎会自动识别入口节点）
- **配置**：无需配置
- **连线规则**：不可有入边，只能有出边

### 4.2 结束节点 (End)

- **作用**：标记工作流的终点（非必需）
- **配置**：无需配置
- **连线规则**：不可有出边，只能有入边

### 4.3 任务节点 (Task)

- **作用**：调用 Synthos 内置的 Agenda 任务队列执行具体任务
- **可用任务类型**：
  - `ProvideData` - 从 QQ 获取原始聊天记录
  - `Preprocess` - 数据清洗、分组、上下文拼接
  - `AISummarize` - AI 摘要生成
  - `GenerateEmbedding` - 生成向量嵌入
  - `InterestScore` - 计算兴趣度评分
  - `LLMInterestEvaluation` - 基于 LLM 的兴趣评分
  - `RunPipeline` - 运行完整数据处理流程
  - `GenerateReport` - 生成日报/周报/月报
- **配置项**：
  - **任务类型**：从下拉框选择
  - **任务参数**（根据任务类型动态显示）：
    - **ProvideData 参数**：
      - IM 类型：QQ / 微信 / 钉钉（必填）
      - 群组 ID 列表：留空则使用全局默认群组
      - 开始时间戳：留空则自动计算
      - 结束时间戳：留空则使用当前时间
    - **Preprocess / AISummarize 参数**：
      - 群组 ID 列表：留空则使用全局默认群组
      - 开始时间戳：留空则自动计算
      - 结束时间戳：留空则使用当前时间
    - **InterestScore / LLMInterestEvaluation / GenerateEmbedding 参数**：
      - 开始时间戳：留空则自动计算
      - 结束时间戳：留空则使用当前时间
    - **GenerateReport 参数**：
      - 报告类型：日报 / 周报 / 月报（必填）
      - 报告开始时间：报告统计的起始时间戳
      - 报告结束时间：报告统计的结束时间戳
    - **RunPipeline 参数**：无需参数
  - **重试次数**：默认 0（不重试）
  - **超时时间**：单位毫秒，0 表示无超时限制
  - **跳过失败**：开启后，任务失败不会终止整个工作流

> **📌 提示**：未填写的任务参数将使用全局默认值（在"全局参数"按钮中配置）或从执行上下文中自动获取

### 4.4 条件节点 (Condition)

- **作用**：根据上游节点的执行结果决定分支路径
- **条件类型**：
  - `previousNodeSuccess` - 上游节点执行成功
  - `previousNodeFailed` - 上游节点执行失败
  - `keyValueMatch` - 键值匹配（如 `output.status === "ready"`）
  - `customExpression` - 自定义 JavaScript 表达式
- **连线规则**：
  - 出边必须指定 handle（`true` / `false`）
  - 可以有多条出边（多路分支）

### 4.5 并行节点 (Parallel)

- **作用**：标记并行分支的起始/结束点
- **使用场景**：
  - 多个独立任务可以同时执行时（如 GenerateEmbedding 和 InterestScore）
  - 提高执行效率
- **注意**：并行节点会等待所有上游节点完成后才继续

### 4.6 脚本节点 (Script)

- **作用**：执行自定义 JavaScript 代码
- **使用场景**：
  - 数据转换
  - 简单的业务逻辑
  - 日志输出
- **可用上下文**：
  - `context` - 执行上下文对象，可访问上游节点输出
  - `logger` - 日志对象
- **示例**：
  ```javascript
  // 获取上游节点的输出
  const provideDataOutput = context.getUpstreamOutput('provide-data');
  
  // 输出日志
  logger.info('处理了 ' + provideDataOutput.recordCount + ' 条记录');
  
  // 返回结果
  return { processedCount: provideDataOutput.recordCount };
  ```

### 4.7 HTTP 节点 (HTTP)

- **作用**：调用外部 HTTP API
- **配置项**：
  - **URL**：API 地址
  - **Method**：GET / POST / PUT / DELETE
  - **Headers**：自定义请求头（JSON 格式）
  - **Body**：请求体（仅 POST/PUT）
- **示例**：
  ```json
  {
    "url": "https://api.example.com/notify",
    "method": "POST",
    "headers": {
      "Content-Type": "application/json"
    },
    "body": "{\"message\": \"工作流执行完成\"}"
  }
  ```

---

## 5. 创建和编辑工作流

### 5.1 创建新工作流

1. 点击画布顶部的 **"新建工作流"** 按钮
2. 输入工作流名称和描述
3. 从左侧节点面板拖拽节点到画布
4. 连接节点（从源节点的 handle 拖拽到目标节点）
5. 选中节点，在右侧属性面板中配置参数
6. 点击 **"保存"** 按钮

### 5.2 编辑现有工作流

1. 在工作流选择器中选择要编辑的工作流
2. 在画布上修改节点和连线
3. 修改节点属性
4. 点击 **"保存"** 按钮

### 5.3 保存流程（Diff 确认）

点击保存后，系统会弹出 **Diff 对比窗口**，展示新旧配置的差异：

- 绿色背景：新增的配置
- 红色背景：删除的配置
- 黄色背景：修改的配置

确认无误后点击 **"确认保存"**。

### 5.4 删除节点/连线

- **删除节点**：选中节点后按 `Delete` 键，或右键菜单选择 "删除"
- **删除连线**：选中连线后按 `Delete` 键

### 5.5 复制节点

1. 选中节点
2. 右键菜单选择 **"复制节点"**
3. 复制的节点会出现在原节点旁边

### 5.6 配置全局参数

工作流编排系统提供了全局默认参数配置，当任务节点未明确指定参数时，将使用这些默认值。

**如何配置全局参数**：

1. 点击工具栏的 **"全局参数"** 按钮
2. 在弹出的对话框中配置以下参数：
   - **默认时间范围（小时）**：任务未指定时间范围时，自动使用"当前时间 - N 小时"作为时间范围（默认 100 小时）
   - **默认 IM 类型**：ProvideData 任务未指定 IM 类型时使用（默认 QQ）
   - **默认群组 ID 列表**：任务未指定群组列表时使用，留空表示处理所有群组
3. 点击 **"保存"** 按钮

**参数优先级**（从高到低）：
1. 任务节点配置的参数（在右侧属性面板中设置）
2. 执行上下文中的参数（工作流执行时传入）
3. 全局默认参数（在"全局参数"中设置）

> **💡 最佳实践**：
> - 为常用群组配置默认群组列表，避免每个任务节点重复输入
> - 根据业务需求调整默认时间范围，平衡数据量和处理时间
> - 在工作流中只为特殊任务节点指定参数，其他节点使用默认值即可

---

## 6. 运行和监控工作流

### 6.1 手动触发工作流

1. 在工作流选择器中选择要执行的工作流
2. 点击工具栏的 **"手动触发"** 按钮
3. （可选）在弹出的对话框中配置全局变量（如 `startTimeStamp`、`endTimeStamp`）
4. 点击 **"开始执行"**

### 6.2 查看实时执行状态

手动触发后，画布上的节点会实时更新状态：

- 节点边框颜色变化（参考 [3.1 画布区域](#31-画布区域)）
- 顶部工具栏显示当前进度（如 "运行中 (3/8)"）

### 6.3 查看节点输出

1. 选中已完成的节点
2. 在右侧属性面板的 **"执行结果"** 标签页查看：
   - **状态**：成功 / 失败
   - **开始时间** / **完成时间**
   - **输出数据**：JSON 格式
   - **错误信息**（仅失败时）

### 6.4 查看执行历史

1. 打开底部的 **"执行历史"** 面板
2. 点击任意一条历史记录
3. 画布会加载该次执行的快照，节点状态高亮显示

### 6.5 取消正在执行的工作流

1. 确保当前查看的是正在执行的工作流
2. 点击工具栏的 **"取消执行"** 按钮
3. 系统会尝试取消后续节点的执行

### 6.6 断点续跑

如果工作流执行失败（某个节点失败且未设置"跳过失败"），你可以从断点继续执行：

1. 在执行历史中选择失败的记录
2. 修复导致失败的问题（如修改节点配置、检查外部依赖）
3. 点击工具栏的 **"断点续跑"** 按钮
4. 系统会跳过已完成的节点，从失败节点重新执行

---

## 7. 常见场景示例

### 7.1 并行执行独立任务

**场景**：生成向量嵌入和计算兴趣度评分是两个独立的任务，可以并行执行以节省时间。

**流程设计**：
```
[AI 摘要] → [并行起始]
               ↓
         ┌─────┴─────┐
         ↓           ↓
    [生成嵌入]  [兴趣评分]
         ↓           ↓
         └─────┬─────┘
               ↓
          [并行汇聚] → [结束]
```

**配置要点**：
1. 在 AI 摘要节点后添加一个 **并行节点**（起始）
2. 从并行起始节点连接到两个任务节点
3. 添加另一个 **并行节点**（汇聚）作为汇聚点

### 7.2 条件分支（按数据量决定策略）

**场景**：当获取的数据量超过 1000 条时，跳过预处理直接进入摘要生成。

**流程设计**：
```
[提供数据] → [条件判断]
               ↓
         ┌─────┴─────┐
         ↓           ↓
      [预处理]    [AI 摘要]
         ↓           
      [AI 摘要]      
```

**配置要点**：
1. 在提供数据节点后添加 **条件节点**
2. 条件表达式：`keyValueMatch`，匹配条件 `output.recordCount > 1000`
3. true 分支连接到 AI 摘要节点
4. false 分支连接到预处理节点

### 7.3 失败后发送通知

**场景**：当关键任务失败时，通过 HTTP 请求发送通知到企业微信/钉钉。

**流程设计**：
```
[关键任务] → [条件判断]
               ↓
         ┌─────┴─────┐
         ↓           ↓
    [HTTP 通知]   [下一步]
```

**配置要点**：
1. 在关键任务节点后添加 **条件节点**
2. 条件表达式：`previousNodeFailed`
3. true 分支连接到 HTTP 节点，配置通知 API
4. false 分支连接到下一个正常节点

### 7.4 自定义脚本数据转换

**场景**：在摘要生成前，对数据进行自定义清洗。

**流程设计**：
```
[预处理] → [脚本节点：数据清洗] → [AI 摘要]
```

**脚本示例**：
```javascript
// 获取预处理结果
const preprocessOutput = context.getUpstreamOutput('preprocess');
const sessions = preprocessOutput.sessions;

// 过滤掉长度小于 10 的对话
const filteredSessions = sessions.filter(s => s.messageCount >= 10);

logger.info(`过滤前：${sessions.length} 个对话，过滤后：${filteredSessions.length} 个对话`);

// 返回清洗后的数据
return { sessions: filteredSessions };
```

---

## 8. 常见问题

### Q1: 为什么我的工作流无法保存？

**可能原因**：
1. **存在环路**：DAG 不允许环路（即 A → B → C → A）
2. **缺少 start/end 节点**：虽然非必需，但建议添加
3. **连线错误**：start 节点不可有入边，end 节点不可有出边
4. **配置验证失败**：检查节点的参数是否符合 Schema 要求

**解决方法**：
- 使用画布工具栏的 **"校验工作流"** 功能，系统会高亮错误节点
- 查看浏览器控制台的错误信息

### Q2: 工作流执行失败，如何排查？

**排查步骤**：
1. 在执行历史中找到失败的记录
2. 查看失败节点的 **错误信息**（在属性面板的"执行结果"标签页）
3. 如果是任务节点失败，检查对应的 Agenda 任务日志
4. 如果是条件节点，检查条件表达式是否正确
5. 如果是 HTTP 节点，检查 API 地址和参数

### Q3: 如何修改默认工作流的触发频率？

默认工作流的触发频率由配置文件控制：

1. 打开配置面板（`http://localhost:5173/config`）
2. 找到 `orchestrator.pipelineIntervalInMinutes` 配置项
3. 修改为你想要的频率（单位：分钟）
4. 保存配置并重启 orchestrator 服务

### Q4: 并行节点的最大并发数是多少？

并行节点的实际并发受 **Agenda 的 `maxConcurrency` 配置** 限制。默认值为 1（串行），如需真正并行，请修改配置文件：

```json
{
  "orchestrator": {
    "maxConcurrency": 5  // 允许最多 5 个任务并行执行
  }
}
```

### Q5: 断点续跑会重复执行已完成的节点吗？

**不会**。断点续跑会从执行快照中恢复状态，跳过所有 `success` / `skipped` 状态的节点，仅重新执行 `failed` / `cancelled` 节点。

### Q6: 如何查看工作流的详细日志？

目前工作流执行日志输出到 orchestrator 的日志文件中。你可以：

1. 在服务器上查看 `logs/orchestrator-*.log` 文件
2. 或通过系统监控页面查看实时日志（筛选 orchestrator 服务）

> **注意**：P4 阶段的日志系统改造（按 executionId 过滤）已暂停实施，日志功能后续会进一步增强。

### Q7: 脚本节点可以使用哪些 Node.js API？

脚本节点在 **Node.js 沙箱环境**中执行，可以使用：
- 所有标准 JavaScript API（如 `Math`、`Date`、`JSON`）
- `context` - 执行上下文（获取上游节点输出）
- `logger` - 日志对象

**不可使用**：
- `require()` / `import` - 无法加载外部模块
- 文件系统 API（`fs`）
- 网络 API（`http` / `https`）- 请使用 HTTP 节点代替

### Q8: 如何备份工作流配置？

工作流配置保存在 `synthos_config.json` 文件的 `orchestrator.workflows` 字段中。备份方法：

1. **手动备份**：复制 `synthos_config.json` 到安全位置
2. **版本控制**：将配置文件纳入 Git 管理（注意排除敏感信息）
3. **自动备份**：使用配置面板的 **"导出配置"** 功能

---

## 📚 延伸阅读

- [Synthos 主文档](../../README.md)
- [工作流编排技术报告](./工作流编排技术报告.md)（面向开发者）
- [API 文档 - Orchestrator RPC 接口](./接口文档/API文档.md#21-orchestrator-rpc-接口)
- [Orchestrator 模块文档](../../applications/orchestrator/README.md)

---

**© 2026 Synthos Project. All Rights Reserved.**
